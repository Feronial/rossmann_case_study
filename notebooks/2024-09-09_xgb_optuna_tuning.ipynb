{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "  return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute Root Mean Square Percentage Error between two arrays.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (array): The array of actual values\n",
    "    y_pred (array): The array of predicted values\n",
    "\n",
    "    Returns:\n",
    "    float: The RMSPE value\n",
    "    \"\"\"\n",
    "    # Ensure that the predicted values are nonzero to avoid division by zero\n",
    "    if np.any(y_pred == 0):\n",
    "        raise ValueError(\"Predicted values contain zero, which would lead to division by zero in RMSPE calculation.\")\n",
    "\n",
    "    # Calculate the percentage errors\n",
    "    percentage_errors = ((y_true - y_pred) / y_true) ** 2\n",
    "\n",
    "    # Compute the mean of the percentage errors\n",
    "    mean_percentage_errors = np.mean(percentage_errors)\n",
    "\n",
    "    # Return the square root of the mean percentage errors, multiplied by 100 (to convert it into a percentage)\n",
    "    return np.sqrt(mean_percentage_errors) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your data is in a CSV file named 'data.csv'\n",
    "data = pd.read_csv('../data/processed/rossmann_sales_df.csv')\n",
    "data = data[data['Open']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by date\n",
    "data.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# Define the split point (e.g., 80% for training)\n",
    "split_index = int(len(data) * 0.8)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = data[:split_index]\n",
    "test_data = data[split_index:]\n",
    "\n",
    "# Separate features (X) and target variable (y) for both sets\n",
    "X_train = train_data.drop(['Date', 'Customers', 'Sales'], axis=1)\n",
    "y_train = train_data['Sales']\n",
    "X_test = test_data.drop(['Date', 'Customers', 'Sales'], axis=1)\n",
    "y_test = test_data['Sales']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to optimize\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000, step=10)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 10)\n",
    "    gamma = trial.suggest_float('gamma', 0, 1)\n",
    "    subsample = trial.suggest_float('subsample', 0.5, 1)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1)\n",
    "    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n",
    "\n",
    "    # Create the XGBoost model with the suggested hyperparameters\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        min_child_weight=min_child_weight,\n",
    "        gamma=gamma,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    rmse_val = rmse(y_test, y_pred)\n",
    "\n",
    "    return rmse_val\n",
    "\n",
    "# Create a study object\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# Run the optimization\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the best hyperparameters\n",
    "best_model = XGBRegressor(**best_params, objective='reg:squarederror', random_state=42)\n",
    "best_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"RMSE: {rmse(y_test, y_pred_best)}\")\n",
    "print(f\"RMSPE: {rmspe(y_test, y_pred_best)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_best)}\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_best)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
